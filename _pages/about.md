---
permalink: /
title: About Me
author_profile: true
---
I am a second-year Ph.D. student from the Department of Computer Science and Engineering at the Ohio State University, advised by Professor [Wei-Lun (Harry) Chao](https://sites.google.com/view/wei-lun-harry-chao). My research interests lie in continual learning, transfer learning and learning with limited & imperfect data.  

I obtained my MASc. from the [University of Toronto](https://www.utoronto.ca/) advised by [Prof. Scott Sanner](https://d3m.mie.utoronto.ca/members/ssanner/). I worked on Continual Learning and Recommender Systems during my master collaborating with [LG AI Research](https://www.lgresearch.ai/).

Prior to that, I  completed my BASc. in [Engineering Science](https://engsci.utoronto.ca/) at the University of Toronto, where I was fortunate to work with [Dr. Erkang Zhu](http://ekzhu.com/).

<!--I worked for [AMD](https://www.amd.com/en), [Pitney Bowes](https://www.pitneybowes.com/us) and [Optimy.ai](Optimy.ai).  -->

<span style="color:red">**I am actively looking for a research internship!**</span>

# News

- <span style="color:#e67300">Oct 2023 — **NeurIPS 2023** Acceptance </span>

  [Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data.](https://neurips.cc/) was accepted to NeurIPS 2023. We address a learning problem involving the adaptation of a pre-trained source model, capable of classifying a wide range of objects to a target domain using
data that covers only a partial label space. 


- <span style="color:#e67300">Oct 2023 — **NeurIPS 2023** Workshop Acceptance </span>

  [Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2305.05803) was accepted to NeurIPS2023 [I Can’t Believe It’s Not Better (ICBINB): Failure Modes in the Age of Foundation Models](https://sites.google.com/view/icbinb-2023/home) Workshoip. We leverage the Segment Anything Model (SAM) to enhanced pseudo labels for Weakly Supervised Semantic Segmentation (WSSS). 
  
- <span style="color:#e67300">Feb 2023 — **CVPR 2023** Acceptance </span>

  [Visual Query Tuning: Towards Effective Usage of Intermediate Representations for Parameter and Memory Efficient Transfer Learning](https://arxiv.org/abs/2212.03220) was accepted to CVPR 2023. We propose visual query tuning (VQT), a simple yet effective approach to aggregate intermediate features of Vision Transformers. 

- <span style="color:#e67300">Oct 2022 — **IPM** Acceptance</span>

  [Unintended Bias in Language Model-driven Conversational Recommendation](https://arxiv.org/abs/2201.06224) was accepted to Information Processing and Management (IPM)!  We investigate how unintended bias — i.e., language variations such as name references or indirect indicators of sexual orientation or location that should not affect recommendations — manifests in significantly shifted price and category distributions of restaurant recommendations


- <span style="color:#e67300">Sept 2022 — **ECCV 2022** Workshop Acceptance</span>

  [TransCAM: Transformer Attention-based CAM Refinement for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.07239) was to the [Learning from Limited and Imperfect Data (L2ID) Workshop](https://l2id.github.io/l2id2022/) at ECCV 2022!  We propose TransCAM, a Conformer-based solution to WSSS that explicitly leverages the attention weights from the transformer branch of the Conformer to refine the CAM generated from the CNN branch. TransCAM is motivated by our observation that attention weights from shallow transformer blocks are able to capture low-level spatial feature similarities while attention weights from deep transformer blocks capture high-level semantic context. 


- <span style="color:#e67300">April 2022 — **SIGIR 2022**  Acceptance</span>

  [Mitigating the Filter Bubble while Maintaining Relevance: Targeted Diversification with VAE-based Recommender Systems](https://sigir.org/sigir2022/) was accepted to ACM SIGIR 2022! In this paper, we propose a novel methodology that trains Concept Activation Vectors (CAVs) for targeted topical dimensions (e.g., political polarization). We then modulate the latent embeddings of user preferences in a state-of-the-art VAE-based recommender system to diversify along the targeted dimension while preserving topical relevance across orthogonal dimensions.
  
  
 
  
  
  
- <span style="color:#e67300">Jan 2022 — **WWW 2022**  Acceptance</span>

  [Distributional Contrastive Embedding for Clarification-based Conversational Critiquing](https://ssanner.github.io/papers/www22_dcevae.pdf) was accepted to International World Wide Web Conference (WWW) 2022! In this paper, we propose a novel clarification-based conversational critiquing framework that allows the system to clarify user preferences by using distributional embeddings that can capture the specificity and generality of concepts through distributional coverage. 
  
  
  
  
  
- <span style="color:#e67300">Nov 2021 — **Artificial Intelligence** Journal Acceptance</span>

  [CVPR 2020 continual learning in computer vision competition: Approaches, results, current challenges and future directions](https://www.sciencedirect.com/science/article/abs/pii/S0004370221001867?dgcid=author) was accepted to Artificial Intelligence!  In this paper, we report the main results of the CVPR 2020 Continual Learning in Computer Vision competition and summarize the winning approaches, current challenges and future research directions.
  
  
  
- <span style="color:#e67300">Oct 2021 — **Neurocomputing** Journal Acceptance</span>

  [Online Continual Learning in Image Classification: An Empirical Survey](https://www.sciencedirect.com/science/article/abs/pii/S0925231221014995) was accepted to Neurocomputing! We empirically scrutinize recently proposed methods and tricks in Online Continual Learning to study their relative advantages and the settings where they work best. We also discuss recent trends and emerging directions in Online Continual Learning. 
  
  
  
- <span style="color:#e67300">April 2021 — **CVPR 2021** Workshop Acceptance</span> 

  Our paper [Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning](https://arxiv.org/abs/2103.13885) was accepted to the [Workshop on Continual Learning in Computer Vision](https://sites.google.com/view/clvision2021/) at **CVPR 2021**! We leverage supervised contrastive learning and nearest class mean classifier to obtain new state-of-the-art performance for online continual learning. 
  
  

- <span style="color:#e67300">Dec 2020 — **AAAI 2021** Acceptance</span>

  Our paper [Online Class-Incremental Continual Learning with Adversarial Shapley Value](http://128.84.4.34/abs/2009.00093) was accepted to **AAAI 2021**! We contribute a novel Adversarial Shapley value scoring method that scores memory data samples according to their ability to preserve latent decision boundaries for previously observed classes (to maintain learning stability and avoid forgetting) while interfering with latent decision boundaries of current classes being learned (to encourage plasticity and optimal learning of new class boundaries). 

  

- <span style="color:#e67300">Nov 2020 — **ICDM 2020** Workshop Acceptance</span>

  Our paper [Attentive Autoencoders for Multifaceted Preference Learning in One-class Collaborative Filtering](https://arxiv.org/abs/2010.12803) (with [Ga Wu](https://wuga214.github.io/), [Kai Luo](https://scholar.google.com/citations?user=lO1PU44AAAAJ&hl=en), [Scott Sanner](https://d3m.mie.utoronto.ca/members/ssanner/)) was aceepted to the [Workshop on Advanced Neural Algorithms and Theories for Recommender Systems (NeuRec)](https://datasj.github.io/) at **ICDM 2020**!

  

- <span style="color:#e67300">June 2020 — **CVPR 2020** CLVision Challenge Champion</span>

  I **won 1st  place** in the **CVPR 2020** [CLVision Challenge](https://sites.google.com/view/clvision2020/challenge/challenge-winners) with my entry [Batch-level Experience Replay with Review for Continual Learning](https://arxiv.org/abs/2007.05683)! Welcome to check our winning solution [[code]](https://github.com/RaptorMai/CVPR20_CLVision_challenge) [[paper]](https://arxiv.org/abs/2007.05683) and the [summary](https://arxiv.org/abs/2009.09929) of the challenge.

  

# Contact

Email: mai.145@osu.edu

